---
---
@article{SilvaRMCSNMN23,
  author    = {Cleber A. C. F. da Silva and
               Daniel Carneiro Rosa and
               P{\'{e}}ricles B. C. de Miranda and
               Filipe R. Cordeiro and
               Tapas Si and
               Andr{\'{e}} C. A. Nascimento and
               Rafael Ferreira Leite de Mello and
               Paulo S. G. de Mattos Neto},
  title     = {A novel multi-objective grammar-based framework for the generation
               of Convolutional Neural Networks},
  journal   = {Expert Syst. Appl.},
  abbr      = {ESA},
  volume    = {212},
  pages     = {118670},
  year      = {2023},
  url       = {https://doi.org/10.1016/j.eswa.2022.118670},
  doi       = {10.1016/j.eswa.2022.118670},
  timestamp = {Tue, 06 Dec 2022 13:15:00 +0100},
  biburl    = {https://dblp.org/rec/journals/eswa/SilvaRMCSNMN23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract  = {{In recent years, the adoption of deep Convolutional Neural Networks (CNNs) has stood out in solving computer vision tasks, such as image classification. Researchers have proposed several architectures with varying sizes, complexities, and an increasing number of trainable parameters. For this reason, finding an optimized configuration and architecture with reduced complexity and high performance has become a very difficult task, since these configurations are totally dependent on the target classification problem and mostly depend on the optimization of a specialist in the area. To assist in the search for these optimal configurations, this work proposes the use of a multi-objective grammatical evolution framework, composed of a multi-objective search engine, a new context-free grammar responsible for creating the problem search space and a process mapping of individuals. Such a framework automatically generates and optimizes CNNs for a given image classification problem, without the need for human intervention from an expert. The framework navigates the search space using two objective functions seeking to maximize two metrics: accuracy and -score. The proposal was validated in the CIFAR-10, CIFAR-100, MNIST, KMNIST and EuroSAT datasets and the results show that the proposed method is able to generate simpler networks, but that statistically outperform (more complex) state-of-the-art CNNs in both metrics considered in the study.}}
}


@article{CordeiroSBRC23,
  author    = {Filipe R. Cordeiro and
               Ragav Sachdeva and
               Vasileios Belagiannis and
               Ian D. Reid and
               Gustavo Carneiro},
  title     = {LongReMix: Robust learning with high confidence samples in a noisy
               label environment},
  journal   = {Pattern Recognit.},
  abbr = {PR},
  volume    = {133},
  pages     = {109013},
  year      = {2023},
  url       = {https://doi.org/10.1016/j.patcog.2022.109013},
  doi       = {10.1016/j.patcog.2022.109013},
  timestamp = {Tue, 08 Nov 2022 21:43:05 +0100},
  biburl    = {https://dblp.org/rec/journals/pr/CordeiroSBRC23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract  = {{State-of-the-art noisy-label learning algorithms rely on an unsupervised learning to classify training samples as clean or noisy, followed by a semi-supervised learning (SSL) that minimises the empirical vicinal risk using a labelled set formed by samples classified as clean, and an unlabelled set with samples classified as noisy. The classification accuracy of such noisy-label learning methods depends on the precision of the unsupervised classification of clean and noisy samples, and the robustness of SSL to small clean sets. We address these points with a new noisy-label training algorithm, called LongReMix, which improves the precision of the unsupervised classification of clean and noisy samples and the robustness of SSL to small clean sets with a two-stage learning process. The stage one of LongReMix finds a small but precise high-confidence clean set, and stage two augments this high-confidence clean set with new clean samples and oversamples the clean data to increase the robustness of SSL to small clean sets. We test LongReMix on CIFAR-10 and CIFAR-100 with introduced synthetic noisy labels, and the real-world noisy-label benchmarks CNWL (Red Mini-ImageNet), WebVision, Clothing1M, and Food101-N. The results show that our LongReMix produces significantly better classification accuracy than competing approaches, particularly in high noise rate problems. Furthermore, our approach achieves state-of-the-art performance in most datasets. }},
  code      = {https://github.com/filipe-research/LongReMix},
  arxiv     = {https://arxiv.org/abs/2103.04173}
}

@article{SachdevaCBRC23,
  author    = {Ragav Sachdeva and
               Filipe Rolim Cordeiro and
               Vasileios Belagiannis and
               Ian Reid and
               Gustavo Carneiro},
  title     = {ScanMix: Learning from Severe Label Noise via Semantic Clustering
               and Semi-Supervised Learning},
  journal   = {Pattern Recognit.},
  abbr      = {PR},
  volume    = {134},
  pages     = {109121},
  year      = {2023},
  url       = {https://doi.org/10.1016/j.patcog.2022.109121},
  doi       = {10.1016/j.patcog.2022.109121},
  timestamp = {Sun, 25 Dec 2022 14:03:34 +0100},
  biburl    = {https://dblp.org/rec/journals/pr/SachdevaCBRC23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract  = {We propose a new training algorithm, ScanMix, that explores semantic clustering and semi-supervised learning (SSL) to allow superior robustness to severe label noise and competitive robustness to non-severe label noise problems, in comparison to the state of the art (SOTA) methods. ScanMix is based on the expectation maximisation framework, where the E-step estimates the latent variable to cluster the training images based on their appearance and classification results, and the M-step optimises the SSL classification and learns effective feature representations via semantic clustering. We present a theoretical result that shows the correctness and convergence of ScanMix, and an empirical result that shows that ScanMix has SOTA results on CIFAR-10/-100 (with symmetric, asymmetric and semantic label noise), Red Mini-ImageNet (from the Controlled Noisy Web Labels), Clothing1M and WebVision. In all benchmarks with severe label noise, our results are competitive to the current SOTA.},
  arxiv     = {https://arxiv.org/abs/2103.11395},
  code      = {https://github.com/ragavsachdeva/ScanMix}
}

@inproceedings{studynoisy2022,
  author    = {Emeson Santana and
               Gustavo Carneiro and
               Filipe R. Cordeiro},
  title     = {A Study on the Impact of Data Augmentation for Training Convolutional
               Neural Networks in the Presence of Noisy Labels},
  journal   = {CoRR},
  abbr      = {SIBGRAPI},
  volume    = {abs/2208.11176},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2208.11176},
  doi       = {10.48550/arXiv.2208.11176},
  eprinttype = {arXiv},
  eprint    = {2208.11176},
  timestamp = {Mon, 29 Aug 2022 15:51:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2208-11176.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract  = {{Label noise is common in large real-world datasets, and its presence harms the training process of deep neural networks. Although several works have focused on the training strategies to address this problem, there are few studies that evaluate the impact of data augmentation as a design choice for training deep neural networks. In this work, we analyse the model robustness when using different data augmentations and their improvement on the training with the presence of noisy labels. We evaluate state-of-the-art and classical data augmentation strategies with different levels of synthetic noise for the datasets MNist, CIFAR-10, CIFAR-100, and the real-world dataset Clothing1M. We evaluate the methods using the accuracy metric. Results show that the appropriate selection of data augmentation can drastically improve the model robustness to label noise, increasing up to 177.84% of relative best test accuracy compared to the baseline with no augmentation, and an increase of up to 6% in absolute value with the state-of-the-art DivideMix training strategy.}},
  arxiv   = {https://arxiv.org/abs/2208.11176}
}

@inproceedings{sampaio2022study,
  title={A Study on Class Activation Map Methods to Detect Masses in Mammography Images using Weakly Supervised Learning},
  author={Sampaio, Vicente and Cordeiro, Filipe R},
  booktitle={Anais do XIX Encontro Nacional de Intelig{\^e}ncia Artificial e Computacional},
  pages={437--448},
  year={2022},
  abbr = {ENIAC},
  abstract = {{Nos últimos anos, modelos de aprendizado fracamente supervisionado têm auxiliado na detecção de lesões em imagens de mamografia, diminuindo a necessidade de anotações de pixels na imagem. A maioria dos modelos na literatura se baseia no uso de mapas de ativação CAM, não sendo explorado o uso de outros modelos de ativação para detecção em imagens de mamografia. Este trabalho apresenta um estudo do uso de diferentes métodos de mapas de ativação do estado da arte, aplicados para treinamento fracamente supervisionado em imagens de mamografia. Neste estudo, comparamos os métodos CAM, GradCAM, GradCAM++, XGradCAM e LayerCAM, utilizando a rede GMIC para detectar a presença de lesões em imagens de mamografia. A avaliação é feita utilizando a base VinDr-Mammo, utilizando as métricas de Acurácia, TPR, FNR e FPPI. Resultados mostram que o uso de diferentes estratégias de mapas de ativação nas etapas de treino e teste melhoram o resultado do modelo. Com isso, melhoramos os resultados do método GMIC, reduzindo o valor de FPPI e aumentando o valor de TPR.}}
}

@article{DiasMNCMP21,
  author    = {Lucas V. Dias and
               P{\'{e}}ricles B. C. de Miranda and
               Andr{\'{e}} C. A. Nascimento and
               Filipe R. Cordeiro and
               Rafael Ferreira Mello and
               Ricardo B. C. Prud{\^{e}}ncio},
  title     = {ImageDataset2Vec: An image dataset embedding for algorithm selection},
  journal   = {Expert Syst. Appl.},
  abbr = {ESA},
  volume    = {180},
  pages     = {115053},
  year      = {2021},
  url       = {https://doi.org/10.1016/j.eswa.2021.115053},
  doi       = {10.1016/j.eswa.2021.115053},
  timestamp = {Thu, 14 Oct 2021 08:46:34 +0200},
  biburl    = {https://dblp.org/rec/journals/eswa/DiasMNCMP21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {{Convolutional Neural Networks (CNNs) have become the main solution for image classification tasks in different applications. Although several CNN architectures are available, there is no best architecture regardless the problem at hand. The selection of the most suitable CNN architecture is usually performed by trial and error, which may take much time and computational resources. Meta-learning (MtL) is a framework developed in machine learning to perform algorithm selection based on the meta-features of each task being solved. Such meta-features are usually descriptive characteristics extracted from the training dataset available in the task at hand. Despite the increasing attention of MtL for algorithm selection, its success strongly depends on defining relevant meta-features to represent the classification tasks of interest. This paper proposes the ImageDataset2Vec method for extracting meta-features to describe image classification datasets. ImageDataset2Vec adopts a pre-trained deep neural network to extract features from images datasets, embedding them in a single feature vector. The derived meta-features are employed by MtL to select CNN architectures for image classification. The proposed approach was evaluated for selecting among six CNN algorithms in 45 two-classes image datasets. The results showed that MtL using ImageDataset2Vec overcame different baseline methods, selecting the best possible CNN algorithm in  of the datasets. Furthermore, the proposal was statistically equivalent to the ground truth when the best CNN is recommended, i.e., when MtL does not select the best CNN, it selects a competitive algorithm. These results show that the proposal was able to extract representative features from image datasets.}}
}


