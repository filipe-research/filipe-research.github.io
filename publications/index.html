<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Filipe Cordeiro | publications</title>
  <meta name="description" content="This is the personal website of Filipe Cordeiro">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="https://filipe-research.github.io//assets/css/all.min.css">
  <link rel="stylesheet" href="https://filipe-research.github.io//assets/css/academicons.min.css">
  <link rel="stylesheet" href="https://filipe-research.github.io//assets/css/main.css">
  <link rel="canonical" href="https://filipe-research.github.io//publications/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="https://filipe-research.github.io//"><span class="font-weight-bold">Filipe</span> Cordeiro</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="https://filipe-research.github.io//">
              about
              
            </a>
          </li>
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="https://filipe-research.github.io//cv/">
                    curriculum vitae
                    
                  </a>
              </li>
            
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="https://filipe-research.github.io//projects/">
                    projects
                    
                  </a>
              </li>
            
          
            
              <li class="nav-item navbar-active font-weight-bold">
                  <a class="nav-link" href="https://filipe-research.github.io//publications/">
                    publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
              </li>
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="https://filipe-research.github.io//teaching/">
                    teaching
                    
                  </a>
              </li>
            
          
            
          
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>publications</h1>
  <h6><nobr><em>*</em></nobr> denotes equal contribution and joint lead authorship.</h6>


<p><br /></p>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.sciencedirect.com/journal/expert-systems-with-applications" target="_blank">
          ESA
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="SilvaRMCSNMN23" class="col p-0">
      <h5 class="title mb-0">A novel multi-objective grammar-based framework for the generation
               of Convolutional Neural Networks.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Cleber A. C. F. Silva,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Daniel Carneiro Rosa,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Péricles B. C. Miranda,</nobr>
                
              
            
          
        
          
            
              
                <nobr><em>Filipe R. Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Tapas Si,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>André C. A. Nascimento,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Rafael Ferreira Leite Mello,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Paulo S. G. Mattos Neto</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Expert Syst. Appl.
          
          
            2023.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#SilvaRMCSNMN23-abstract" role="button" aria-expanded="false" aria-controls="SilvaRMCSNMN23-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="SilvaRMCSNMN23-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            In recent years, the adoption of deep Convolutional Neural Networks (CNNs) has stood out in solving computer vision tasks, such as image classification. Researchers have proposed several architectures with varying sizes, complexities, and an increasing number of trainable parameters. For this reason, finding an optimized configuration and architecture with reduced complexity and high performance has become a very difficult task, since these configurations are totally dependent on the target classification problem and mostly depend on the optimization of a specialist in the area. To assist in the search for these optimal configurations, this work proposes the use of a multi-objective grammatical evolution framework, composed of a multi-objective search engine, a new context-free grammar responsible for creating the problem search space and a process mapping of individuals. Such a framework automatically generates and optimizes CNNs for a given image classification problem, without the need for human intervention from an expert. The framework navigates the search space using two objective functions seeking to maximize two metrics: accuracy and -score. The proposal was validated in the CIFAR-10, CIFAR-100, MNIST, KMNIST and EuroSAT datasets and the results show that the proposed method is able to generate simpler networks, but that statistically outperform (more complex) state-of-the-art CNNs in both metrics considered in the study.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.sciencedirect.com/journal/pattern-recognition" target="_blank">
          PR
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="CordeiroSBRC23" class="col p-0">
      <h5 class="title mb-0">LongReMix: Robust learning with high confidence samples in a noisy
               label environment.</h5>
      <div class="author">
        
          
            
              
                <nobr><em>Filipe R. Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Ragav Sachdeva,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Vasileios Belagiannis,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Ian D. Reid,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Gustavo Carneiro</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Pattern Recognit.
          
          
            2023.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#CordeiroSBRC23-abstract" role="button" aria-expanded="false" aria-controls="CordeiroSBRC23-abstract">Abstract</a>
        
        
        
        
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/filipe-research/LongReMix" target="_blank">Code</a>
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/https://arxiv.org/abs/2103.04173" target="_blank">arXiv</a>
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="CordeiroSBRC23-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            State-of-the-art noisy-label learning algorithms rely on an unsupervised learning to classify training samples as clean or noisy, followed by a semi-supervised learning (SSL) that minimises the empirical vicinal risk using a labelled set formed by samples classified as clean, and an unlabelled set with samples classified as noisy. The classification accuracy of such noisy-label learning methods depends on the precision of the unsupervised classification of clean and noisy samples, and the robustness of SSL to small clean sets. We address these points with a new noisy-label training algorithm, called LongReMix, which improves the precision of the unsupervised classification of clean and noisy samples and the robustness of SSL to small clean sets with a two-stage learning process. The stage one of LongReMix finds a small but precise high-confidence clean set, and stage two augments this high-confidence clean set with new clean samples and oversamples the clean data to increase the robustness of SSL to small clean sets. We test LongReMix on CIFAR-10 and CIFAR-100 with introduced synthetic noisy labels, and the real-world noisy-label benchmarks CNWL (Red Mini-ImageNet), WebVision, Clothing1M, and Food101-N. The results show that our LongReMix produces significantly better classification accuracy than competing approaches, particularly in high noise rate problems. Furthermore, our approach achieves state-of-the-art performance in most datasets. 
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.sciencedirect.com/journal/pattern-recognition" target="_blank">
          PR
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="SachdevaCBRC23" class="col p-0">
      <h5 class="title mb-0">ScanMix: Learning from Severe Label Noise via Semantic Clustering
               and Semi-Supervised Learning.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Ragav Sachdeva,</nobr>
                
              
            
          
        
          
            
              
                <nobr><em>Filipe Rolim Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Vasileios Belagiannis,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Ian Reid,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Gustavo Carneiro</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Pattern Recognit.
          
          
            2023.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#SachdevaCBRC23-abstract" role="button" aria-expanded="false" aria-controls="SachdevaCBRC23-abstract">Abstract</a>
        
        
        
        
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/ragavsachdeva/ScanMix" target="_blank">Code</a>
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/https://arxiv.org/abs/2103.11395" target="_blank">arXiv</a>
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="SachdevaCBRC23-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            We propose a new training algorithm, ScanMix, that explores semantic clustering and semi-supervised learning (SSL) to allow superior robustness to severe label noise and competitive robustness to non-severe label noise problems, in comparison to the state of the art (SOTA) methods. ScanMix is based on the expectation maximisation framework, where the E-step estimates the latent variable to cluster the training images based on their appearance and classification results, and the M-step optimises the SSL classification and learns effective feature representations via semantic clustering. We present a theoretical result that shows the correctness and convergence of ScanMix, and an empirical result that shows that ScanMix has SOTA results on CIFAR-10/-100 (with symmetric, asymmetric and semantic label noise), Red Mini-ImageNet (from the Controlled Noisy Web Labels), Clothing1M and WebVision. In all benchmarks with severe label noise, our results are competitive to the current SOTA.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://sibgrapi.sbc.org.br/" target="_blank">
          SIBGRAPI
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="studynoisy2022" class="col p-0">
      <h5 class="title mb-0">A Study on the Impact of Data Augmentation for Training Convolutional
               Neural Networks in the Presence of Noisy Labels.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Emeson Santana,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Gustavo Carneiro,</nobr>
                
              
            
          
        
          
            
              and
              
                <nobr><em>Filipe R. Cordeiro</em>.</nobr>
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In SIBGRAPI
          
          
            2022.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#studynoisy2022-abstract" role="button" aria-expanded="false" aria-controls="studynoisy2022-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/https://arxiv.org/abs/2208.11176" target="_blank">arXiv</a>
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="studynoisy2022-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Label noise is common in large real-world datasets, and its presence harms the training process of deep neural networks. Although several works have focused on the training strategies to address this problem, there are few studies that evaluate the impact of data augmentation as a design choice for training deep neural networks. In this work, we analyse the model robustness when using different data augmentations and their improvement on the training with the presence of noisy labels. We evaluate state-of-the-art and classical data augmentation strategies with different levels of synthetic noise for the datasets MNist, CIFAR-10, CIFAR-100, and the real-world dataset Clothing1M. We evaluate the methods using the accuracy metric. Results show that the appropriate selection of data augmentation can drastically improve the model robustness to label noise, increasing up to 177.84% of relative best test accuracy compared to the baseline with no augmentation, and an increase of up to 6% in absolute value with the state-of-the-art DivideMix training strategy.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="" target="_blank">
          ENIAC
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="sampaio2022study" class="col p-0">
      <h5 class="title mb-0">A Study on Class Activation Map Methods to Detect Masses in Mammography Images using Weakly Supervised Learning.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Vicente Sampaio,</nobr>
                
              
            
          
        
          
            
              and
              
                <nobr><em>Filipe R Cordeiro</em>.</nobr>
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Anais do XIX Encontro Nacional de Inteligência Artificial e Computacional
          
          
            2022.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#sampaio2022study-abstract" role="button" aria-expanded="false" aria-controls="sampaio2022study-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="sampaio2022study-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Nos últimos anos, modelos de aprendizado fracamente supervisionado têm auxiliado na detecção de lesões em imagens de mamografia, diminuindo a necessidade de anotações de pixels na imagem. A maioria dos modelos na literatura se baseia no uso de mapas de ativação CAM, não sendo explorado o uso de outros modelos de ativação para detecção em imagens de mamografia. Este trabalho apresenta um estudo do uso de diferentes métodos de mapas de ativação do estado da arte, aplicados para treinamento fracamente supervisionado em imagens de mamografia. Neste estudo, comparamos os métodos CAM, GradCAM, GradCAM++, XGradCAM e LayerCAM, utilizando a rede GMIC para detectar a presença de lesões em imagens de mamografia. A avaliação é feita utilizando a base VinDr-Mammo, utilizando as métricas de Acurácia, TPR, FNR e FPPI. Resultados mostram que o uso de diferentes estratégias de mapas de ativação nas etapas de treino e teste melhoram o resultado do modelo. Com isso, melhoramos os resultados do método GMIC, reduzindo o valor de FPPI e aumentando o valor de TPR.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2021</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.sciencedirect.com/journal/expert-systems-with-applications" target="_blank">
          ESA
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="DiasMNCMP21" class="col p-0">
      <h5 class="title mb-0">ImageDataset2Vec: An image dataset embedding for algorithm selection.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Lucas V. Dias,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Péricles B. C. Miranda,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>André C. A. Nascimento,</nobr>
                
              
            
          
        
          
            
              
                <nobr><em>Filipe R. Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Rafael Ferreira Mello,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Ricardo B. C. Prudêncio</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Expert Syst. Appl.
          
          
            2021.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#DiasMNCMP21-abstract" role="button" aria-expanded="false" aria-controls="DiasMNCMP21-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="DiasMNCMP21-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Convolutional Neural Networks (CNNs) have become the main solution for image classification tasks in different applications. Although several CNN architectures are available, there is no best architecture regardless the problem at hand. The selection of the most suitable CNN architecture is usually performed by trial and error, which may take much time and computational resources. Meta-learning (MtL) is a framework developed in machine learning to perform algorithm selection based on the meta-features of each task being solved. Such meta-features are usually descriptive characteristics extracted from the training dataset available in the task at hand. Despite the increasing attention of MtL for algorithm selection, its success strongly depends on defining relevant meta-features to represent the classification tasks of interest. This paper proposes the ImageDataset2Vec method for extracting meta-features to describe image classification datasets. ImageDataset2Vec adopts a pre-trained deep neural network to extract features from images datasets, embedding them in a single feature vector. The derived meta-features are employed by MtL to select CNN architectures for image classification. The proposed approach was evaluated for selecting among six CNN algorithms in 45 two-classes image datasets. The results showed that MtL using ImageDataset2Vec overcame different baseline methods, selecting the best possible CNN algorithm in  of the datasets. Furthermore, the proposal was statistically equivalent to the ground truth when the best CNN is recommended, i.e., when MtL does not select the best CNN, it selects a competitive algorithm. These results show that the proposal was able to extract representative features from image datasets.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="www.bmva.org/bmvc" target="_blank">
          BMVC
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="CordeiroB0C21" class="col p-0">
      <h5 class="title mb-0">PropMix: Hard Sample Filtering and Proportional MixUp for Learning
               with Noisy Labels.</h5>
      <div class="author">
        
          
            
              
                <nobr><em>Filipe Rolim Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Vasileios Belagiannis,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Ian Reid,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Gustavo Carneiro</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In 32nd British Machine Vision Conference 2021, BMVC 2021, Online,
               November 22-25, 2021
          
          
            2021.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#CordeiroB0C21-abstract" role="button" aria-expanded="false" aria-controls="CordeiroB0C21-abstract">Abstract</a>
        
        
        
        
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/filipe-research/PropMix" target="_blank">Code</a>
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/https://arxiv.org/abs/2110.11809" target="_blank">arXiv</a>
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="CordeiroB0C21-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            The most competitive noisy label learning methods rely on an unsupervised classification of clean and noisy samples, where samples classified as noisy are re-labelled
and "MixMatched" with the clean samples. These methods have two issues in large
noise rate problems: 1) the noisy set is more likely to contain hard samples that are incorrectly re-labelled, and 2) the number of samples produced by MixMatch tends to be
reduced because it is constrained by the small clean set size. In this paper, we introduce
the learning algorithm PropMix to handle the issues above. PropMix filters out hard
noisy samples, with the goal of increasing the likelihood of correctly re-labelling the
easy noisy samples. Also, PropMix places clean and re-labelled easy noisy samples in
a training set that is augmented with MixUp, removing the clean set size constraint and
including a large proportion of correctly re-labelled easy noisy samples. We also include
self-supervised pre-training to improve robustness to high noisy label scenarios. Our
experiments show that PropMix has state-of-the-art (SOTA) results on CIFAR-10/-100
(with symmetric, asymmetric and semantic label noise), Red Mini-ImageNet (from the
Controlled Noisy Web Labels), Clothing1M and WebVision. In severe label noise benchmarks, our results are substantially better than other methods. 
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;">
          CEC
        </span>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="SilvaRMCSNMN21" class="col p-0">
      <h5 class="title mb-0">A Multi-Objective Grammatical Evolution Framework to Generate Convolutional
               Neural Network Architectures.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Cleber A. C. F. Silva,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Daniel Carneiro Rosa,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Péricles B. C. Miranda,</nobr>
                
              
            
          
        
          
            
              
                <nobr><em>Filipe R. Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Tapas Si,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>André C. A. Nascimento,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Rafael Ferreira Leite Mello,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Paulo S. G. Mattos Neto</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In IEEE Congress on Evolutionary Computation, CEC 2021, Kraków,
               Poland, June 28 - July 1, 2021
          
          
            2021.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#SilvaRMCSNMN21-abstract" role="button" aria-expanded="false" aria-controls="SilvaRMCSNMN21-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="SilvaRMCSNMN21-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Deep Convolutional Neural Networks (CNNs) have reached the attention in the last decade due to their successful application to many computer vision domains. Several handcrafted architectures have been proposed in the literature, with increasing depth and millions of parameters. However, the optimal architecture size and parameters setup are dataset-dependent and challenging to find. For addressing this problem, this work proposes a Multi-Objective Grammatical Evolution framework to automatically generate suitable CNN architectures (layers and parameters) for a given classification problem. For this, a Context-free Grammar is developed, representing the search space of possible CNN architectures. The proposed method seeks to find suitable network architectures considering two objectives: accuracy and F1-score. We evaluated our method on CIFAR-10, and the results obtained show that our method generates simpler CNN architectures and overcomes the results achieved by larger (more complex) state-of-the-art CNN approaches and other grammars.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;">
          MICCAI
        </span>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="LiuTCBRC21" class="col p-0">
      <h5 class="title mb-0">Self-supervised Mean Teacher for Semi-supervised Chest X-Ray Classification.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Fengbei Liu,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Yu Tian,</nobr>
                
              
            
          
        
          
            
              
                <nobr><em>Filipe R. Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Vasileios Belagiannis,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Ian D. Reid,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Gustavo Carneiro</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Machine Learning in Medical Imaging - 12th International Workshop,
               MLMI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France,
               September 27, 2021, Proceedings
          
          
            2021.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#LiuTCBRC21-abstract" role="button" aria-expanded="false" aria-controls="LiuTCBRC21-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="LiuTCBRC21-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            The training of deep learning models generally requires a large amount of annotated data for effective convergence and generalisation. However, obtaining high-quality annotations is a laboursome and expensive process due to the need of expert radiologists for the labelling task. The study of semi-supervised learning in medical image analysis is then of crucial importance given that it is much less expensive to obtain unlabelled images than to acquire images labelled by expert radiologists. Essentially, semi-supervised methods leverage large sets of unlabelled data to enable better training convergence and generalisation than using only the small set of labelled images. In this paper, we propose Self-supervised Mean Teacher for Semi-supervised (S2MTS2) learning that combines self-supervised mean-teacher pre-training with semi-supervised fine-tuning. The main innovation of S2MTS2 is the self-supervised mean-teacher pre-training based on the joint contrastive learning, which uses an infinite number of pairs of positive query and key features to improve the mean-teacher representation. The model is then fine-tuned using the exponential moving average teacher framework trained with semi-supervised learning. We validate S2MTS2 on the multi-label classification problems from Chest X-ray14 and CheXpert, and the multi-class classification from ISIC2018, where we show that it outperforms the previous SOTA semi-supervised learning methods by a large margin. Our code will be available upon paper acceptance
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://sibgrapi.sbc.org.br/" target="_blank">
          SIBGRAPI
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="SilvaMC21" class="col p-0">
      <h5 class="title mb-0">A New Grammar for Creating Convolutional Neural Networks Applied to
               Medical Image Classification.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Cleber A. C. F. Silva,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Péricles B. C. Miranda,</nobr>
                
              
            
          
        
          
            
              and
              
                <nobr><em>Filipe R. Cordeiro</em>.</nobr>
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In 34th SIBGRAPI Conference on Graphics, Patterns and Images, SIBGRAPI
               2021, Gramado, Rio Grande do Sul, Brazil, October 18-22, 2021
          
          
            2021.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#SilvaMC21-abstract" role="button" aria-expanded="false" aria-controls="SilvaMC21-abstract">Abstract</a>
        
        
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="SilvaMC21-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            In the last decade, the adoption of Deep Convolutional Neural Networks (CNNs) has been successfully applied to solve computer vision tasks, such as image classification in the medical field. However, the several architectures proposed in the literature are composed of an increasing number of parameters and complexity. Therefore, finding the optimal trade-off between accuracy and model complexity for a given data set is challenging. To help the search for these suitable configurations, this work proposes using a new Context-Free Grammar associated with a Multi-Objective Grammatical Evolution Algorithm that generates suitable CNNs for a given image classification problem. In this structure, the new grammar maps every possible search space for the creation of networks. Furthermore, the Multi- Objective Grammatical Evolution Algorithm used optimizes this search taking into account two objective functions: accuracy and F 1 -score. Our proposal was used in three medical image datasets from MedMNIST: PathMNIST, OCTMNIST, and OrganMNIST_Axial. The results showed that our method generated simpler networks with equal or superior performance from state-of-the-art (more complex) networks and others CNNs also generated by grammatical evolution process
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;">
          WACV
        </span>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="SachdevaCBRC21" class="col p-0">
      <h5 class="title mb-0">EvidentialMix: Learning with Combined Open-set and Closed-set Noisy
               Labels.</h5>
      <div class="author">
        
          
            
              
                
                  <nobr>Ragav Sachdeva,</nobr>
                
              
            
          
        
          
            
              
                <nobr><em>Filipe R. Cordeiro</em>,</nobr>
              
            
          
        
          
            
              
                
                  <nobr>Vasileios Belagiannis,</nobr>
                
              
            
          
        
          
            
              
                
                  <nobr>Ian D. Reid,</nobr>
                
              
            
          
        
          
            
              and
              
                
                  <nobr>Gustavo Carneiro</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In IEEE Winter Conference on Applications of Computer Vision, WACV
               2021, Waikoloa, HI, USA, January 3-8, 2021
          
          
            2021.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#SachdevaCBRC21-abstract" role="button" aria-expanded="false" aria-controls="SachdevaCBRC21-abstract">Abstract</a>
        
        
        
        
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https:/github.com/ragavsachdeva/EvidentialMix" target="_blank">Code</a>
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/https://arxiv.org/abs/2011.05704" target="_blank">arXiv</a>
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="SachdevaCBRC21-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            The efficacy of deep learning depends on large-scale data sets that have been carefully curated with reliable data acquisition and annotation processes. However, acquiring such large-scale data sets with precise annotations is very expensive and time-consuming, and the cheap alternatives often yield data sets that have noisy labels. The field has addressed this problem by focusing on training models under two types of label noise: 1) closed-set noise, where some training samples are incorrectly annotated to a training label other than their known true class; and 2) open-set noise, where the training set includes samples that possess a true class that is (strictly) not contained in the set of known training labels. In this work, we study a new variant of the noisy label problem that combines the open-set and closed-set noisy labels, and introduce a benchmark evaluation to assess the performance of training algorithms under this setup. We argue that such problem is more general and better reflects the noisy label scenarios in practice. Furthermore, we propose a novel algorithm, called EvidentialMix, that addresses this problem and compare its performance with the state-of-the-art methods for both closed-set and open-set noise on the proposed benchmark. Our results show that our method produces superior classification results and better feature representations than previous state-of-the-art methods.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2020</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"></ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2019</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"></ol>
    </div>
  </div>



  </div>

  <!-- Footer -->
  <footer>
    &copy; Copyright 2023 Filipe Cordeiro.
    
    
  </footer>

  <!-- Core JavaScript Files -->
  <script src="https://filipe-research.github.io//assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="https://filipe-research.github.io//assets/js/popper.min.js" type="text/javascript"></script>
  <script src="https://filipe-research.github.io//assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="https://filipe-research.github.io//assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="https://filipe-research.github.io//assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="https://filipe-research.github.io//assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
